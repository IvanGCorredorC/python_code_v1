{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# import statsmodels.api as sm\n",
    "# import statistics as stat\n",
    "# import sklearn\n",
    "# import scipy as sy \n",
    "# import plotly.graph_objects as go\n",
    "# from plotly.subplots import make_subplots \n",
    "# import plotly.express as px\n",
    "# from pandas.api.types import CategoricalDtype\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# import collections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cambiar tema del libro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cambiar tema de blanco a negro\n",
    "#! pip install jupyterthemes #este se aplica en anaconda powershell prompt\n",
    "# import jupyterthemes as jt\n",
    "# jt -t\n",
    "#jupyher notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formato de variables\n",
    "reemplazar, separar, convertir a entero, quitar comas, minusculas, mayusculas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df7['clasif_lab'] = pd.Series(df7['clasif_lab'], dtype = \"string\").str.replace('No informa', '-1')\n",
    "#df7['clasif_lab']= pd.Series(df7['clasif_lab'], dtype = \"string\").str.split('.', expand = True).get(0)\n",
    "#df7['clasif_lab'] =pd.Series(df7['clasif_lab'], dtype = \"int\")\n",
    "# otra formapd.Series(clasif_lab.str.split(\".\", expand = True).get(0),dtype=\"int\")\n",
    "##df3[\"sexo\"] = df3[\"sexo\"].str.lower()\n",
    "\n",
    "# reemplazar tíldes variable a variable\n",
    "# df3[\"afiliacion\"] = df3[\"afiliacion\"].str.replace(\"í\", \"i\")\n",
    "\n",
    "# df3['edad'] = pd.Series(dfs3['edad'], dtype = \"string\").str.replace('No informa', '-1')\n",
    "# df3['edad']= pd.Series(df3['edad'], dtype = \"string\").str.split('.', expand = True).get(0)\n",
    "# df3['edad'] =pd.Series(df3['edad'], dtype = \"int\")\n",
    "#pd.to_numeric(df7[\"vr_salario\"], downcast=\"float\")s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#volver a minuscula variable a variable\n",
    "#mayus = lambda x: x.str.upper() if (x.dtype == 'string') else x\n",
    "minus = lambda x: x.str.lower() if (x.dtype == 'string') else x\n",
    "#mayus(df7['etnia']).value_counts()\n",
    "#minus(df7['etnia']).value_counts()\n",
    "df7['etnia'] = minus(df7['etnia'])\n",
    "df7['etnia'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# df3 = df3[df3.iloc[:, :] ==\"str\"].apply(lambda x: x.astype(str).str.lower()) #if (x.dtype == \"int\") else x)\n",
    "# df3 =df3.apply(lambda x: x.astype(str).str.replace(\"á\", \"a\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nombre de columnas\n",
    "#df7.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# análisis descriptivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df7.groupby(by=[\"Fecha\"]).aggregate({\"clasif_lab\": [np.size]})\n",
    "#df7.query('((fecha == \"2010-12-31\") & (clasif_lab == \"1\")) | ((fecha == \"2013-12-31\") & (clasif_lab == \"2\")) | ((fecha == \"2016-12-31\") & (clasif_lab == \"1\"))').count()\n",
    "#df7.query('(fecha == \"2016-12-31\") & (13 < edad < 29) & (sexo == \"hombre\") & (clasif_lab == \"1\")')\n",
    "#gener_2013: 128; hora_2010: 248; gene_2016: 37. existen 120 personas que estuvieron ocupadas en 2010 y que no está ocupadas en 2013. Mirarlas por id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df3.iloc[:,:50].isnull().sum().sort_values(ascending = False) #vive_conyugue, beneficiario_sss, vr_rec_pension\n",
    "# df3.iloc[:,51:100].isnull().sum().sort_values(ascending = False)\n",
    "# df3.iloc[:,101:151].isnull().sum().sort_values(ascending = False)\n",
    "# # df3.iloc[:,152:180].isnull().sum().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyp_2016.shape\n",
    "#Hyp_2016.head()\n",
    "#print(Hyp_2013['llave_n16'].duplicated().sum())\n",
    "# print(Hyp_2013['consecutivo_l'].duplicated().sum())\n",
    "# print(Hyp_2013[\"llave_ID_lb\"].isnull().sum())\n",
    "# print(Hyp_2013[\"llave_ID_lb\"].count())\n",
    "# print(Hyp_2013['indicator_column'].value_counts())\n",
    "#xxx\n",
    "#Hyp_2013 = Hyp_2013.dropna(subset = ['llave_ID_lb'])\n",
    "#Hyp_2016 = Hyp_2016.set_index('llave_ID_lb')\n",
    "#len(aparecen_3veces)\n",
    "#type(Hyp_2016)\n",
    "#Hyp_2010.info()\n",
    "#sorted(Hyp_2010.columns)\n",
    "#pd.Series(Hyp_2010.columns).nunique()\n",
    "#df3.query('(fecha == \"2016-12-31\") | (fecha == \"2013-12-31\") | (fecha == \"2010-12-31\")').count() \n",
    "#mask_1 = df2['ID'].value_counts()==1\n",
    "#mask_1[mask_1==True].count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
