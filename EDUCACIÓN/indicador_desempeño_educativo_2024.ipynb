{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cargue de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rutas\n",
    "p1 = \"C:/Users/ivan.corredor/2024/IGED_desempeño/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "icfes_f = pd.read_csv(p1 + \"RUV_SIMAT_ICFES_FINAL_2024\", sep= \";\",  low_memory=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "icfes_f[\"CICLO_VITAL\"].value_counts() \n",
    "#icfes_f[\"COLE_DEPTO_UBICACION\"].value_counts() \n",
    "#icfes_f.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ESTU_TIPODOCUMENTO', 'ESTU_DOCUMENTO', 'ESTU_FECHANACIMIENTO',\n",
       "       'ESTU_DEPTO_RESIDE', 'ESTU_MCPIO_RESIDE', 'ESTU_GENERO',\n",
       "       'GRUPO_ETCNICO_SIMAT', 'TIPO_DISCA_SIMAT', 'DISCA_SIMAT', 'EDAD_SIMAT',\n",
       "       'ESTRATO_SIMAT', 'ESTU_GRADO', 'COLE_NOMBRE_ESTABLECIMIENTO',\n",
       "       'COLE_NOMBRE_SEDE', 'COLE_CALENDARIO', 'COLE_GENERO', 'COLE_JORNADA',\n",
       "       'COLE_NATURALEZA', 'COLE_AREA_UBICACION', 'COLE_COD_DEPTO_UBICACION',\n",
       "       'COLE_DEPTO_UBICACION', 'COLE_COD_MCPIO_UBICACION',\n",
       "       'COLE_MCPIO_UBICACION', 'HV5', 'VICTIMA', 'NO_VICTIMA', 'PUNT_GLOBAL',\n",
       "       'PERCENTIL_GLOBAL'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "icfes_f.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VICTIMA\n",
       "0    463314\n",
       "1    104592\n",
       "Name: DISCA_SIMAT, dtype: int64"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## observar si existen datos para no víctimas y víctimas por variable\n",
    "icfes_f.groupby(\"VICTIMA\")[\"DISCA_SIMAT\"].apply(lambda x: np.sum(~x.isnull()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "icfes_f[\"COLE_MCPIO_UBICA2\"]= icfes_f[\"COLE_MCPIO_UBICACION\"].replace(\"[' '-.]\", '', regex =True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"formula_G_Hedges.png\" width=\"500\" height=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Media, tamaño universo y varianza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VICTIMA</th>\n",
       "      <th>MEDIA</th>\n",
       "      <th>UNIVERSO</th>\n",
       "      <th>VARIANZA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>257.5</td>\n",
       "      <td>478879.0</td>\n",
       "      <td>2760.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>234.3</td>\n",
       "      <td>104592.0</td>\n",
       "      <td>2111.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VICTIMA  MEDIA  UNIVERSO  VARIANZA\n",
       "0        0  257.5  478879.0    2760.4\n",
       "1        1  234.3  104592.0    2111.4"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Estadísticas necesarias\n",
    "grl_1 = icfes_f.groupby([\"VICTIMA\"]).apply(\n",
    "        lambda x: pd.Series({\n",
    "        'MEDIA': round(x['PUNT_GLOBAL'].mean(), 1),\n",
    "        'UNIVERSO': round(x['PUNT_GLOBAL'].size, 1),\n",
    "        'VARIANZA': round(x['PUNT_GLOBAL'].var(), 1)\n",
    "    })\n",
    "    ).reset_index()\n",
    "grl_1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerador, denominador, G de hedges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NUMERADOR</th>\n",
       "      <th>DENOMINADOR</th>\n",
       "      <th>INDICADOR</th>\n",
       "      <th>INDICADOR_AJUSTADO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23.2</td>\n",
       "      <td>51.420444</td>\n",
       "      <td>0.451182</td>\n",
       "      <td>0.451182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   NUMERADOR  DENOMINADOR  INDICADOR  INDICADOR_AJUSTADO\n",
       "0       23.2    51.420444   0.451182            0.451182"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# crear data frame para el númerador y denominador\n",
    "grl_2 = pd.DataFrame({\"NUMERADOR\": [grl_1.loc[0, \"MEDIA\"] - grl_1.loc[1, \"MEDIA\"]],\n",
    "                      \"DENOMINADOR\": \n",
    "                      [\n",
    "                      np.sqrt(\n",
    "                                (\n",
    "                                    (\n",
    "                                        (grl_1.loc[0, \"UNIVERSO\"] - 1)* grl_1.loc[0, \"VARIANZA\"]\n",
    "                                    )\n",
    "                                    + (\n",
    "                                        (grl_1.loc[1, \"UNIVERSO\"] - 1) * grl_1.loc[1, \"VARIANZA\"]\n",
    "                                    )\n",
    "                                ) \n",
    "                                / (\n",
    "                                    grl_1.loc[0, \"UNIVERSO\"] +\n",
    "                                   grl_1.loc[1, \"UNIVERSO\"] \n",
    "                                   - 2\n",
    "                                )\n",
    "                                )\n",
    "                      ]\n",
    "                     })\n",
    "grl_2[\"INDICADOR\"]  = grl_2[\"NUMERADOR\"] / grl_2[\"DENOMINADOR\"]\n",
    "\n",
    "grl_2[\"INDICADOR_AJUSTADO\"]  = grl_2[\"INDICADOR\"] * ( 1 - \n",
    "                                                        (3 / (\n",
    "                                                                (\n",
    "                                                                    4 * (grl_1.loc[0, \"UNIVERSO\"] + grl_1.loc[1, \"UNIVERSO\"])\n",
    "                                                                ) - 1\n",
    "                                                        )\n",
    "                                                    )\n",
    "                                                    )\n",
    "grl_2\n",
    "\n",
    "#grl = grl.stack()\n",
    "#grl = grl.unstack(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generalización por enfoque"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estadísticos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables\n",
    "names_var = [\"ESTU_GENERO\", \"GRUPO_ETCNICO_SIMAT\", \"DISCA_SIMAT\",\n",
    "             \"ESTRATO_SIMAT\", \n",
    "             \"COLE_NATURALEZA\", \"COLE_AREA_UBICACION\", \n",
    "             \"COLE_DEPTO_UBICACION\", \"COLE_MCPIO_UBICA2\"]#\"EDAD_SIMAT\", #\"ESTU_GRADO\",\n",
    "\n",
    "# tablas de salida\n",
    "tab_out = [\"sex\", \"etni\", \"disca\", \n",
    "            \"estrato\", \n",
    "           \"nat\", \"zona\", \"dpto\", \"mun\"] #\"edad\", #\"grado\",\n",
    "\n",
    "# lista para almacenar las listas de variables\n",
    "ll_var = []\n",
    "\n",
    "# Estadísticas necesarias\n",
    "for g, h in zip(names_var, tab_out):\n",
    "\n",
    "    df = icfes_f.groupby([\"VICTIMA\", g]).apply(\n",
    "        lambda x: pd.Series({\n",
    "            \"MEDIA\": round(x[\"PUNT_GLOBAL\"].mean(), 1),\n",
    "            \"UNIVERSO\": round(x[\"PUNT_GLOBAL\"].size, 1),\n",
    "            \"VARIANZA\": round(x[\"PUNT_GLOBAL\"].var(), 1)\n",
    "        })\n",
    "    )\n",
    "    # Excepción: subselect de muni con no víctimas y víctimas\n",
    "    # obetener valores únicos del nivel 1 del multiindex\n",
    "    if g == \"COLE_MCPIO_UBICA2\":\n",
    "        #filtrar df para municipios con > 3 víctimas\n",
    "        df = df[df[\"UNIVERSO\"] > 3]\n",
    "        paso_1 = df.index.get_level_values('VICTIMA').unique()\n",
    "        # to calculate the number of unique values from the first level for each group in the second level.\n",
    "        paso_2 = df.groupby(level='COLE_MCPIO_UBICA2').apply(lambda x: x.index.get_level_values(0).nunique())\n",
    "        # obtiene indices si el valor de paso_2 (cuenta de municipios) = 2 (longitud nivel 1)\n",
    "        paso_3 = paso_2[paso_2 == len(paso_1)].index.tolist()\n",
    "        # filtra df donde valores del nivel 2 (multiindex) estén en indices de paso_3\n",
    "        df = df[df.index.get_level_values('COLE_MCPIO_UBICA2').isin(paso_3)]\n",
    "    else:\n",
    "        pass\n",
    "    # se crean dfs tab_out_1: \n",
    "    exec(f\"{h}_1 = df.copy()\")\n",
    "    # se crean listas de variables l_tab_out_1:\n",
    "    exec(f\"l_{h}_1 = list(filter(pd.notna, list(df.index.get_level_values(g).unique())))\")\n",
    "    # lista para almacenar las listas anteriores\n",
    "    # eval is used to evaluate a single Python expression or a small block of code represented as a string. \n",
    "    l_var = eval(f\"l_{h}_1\")\n",
    "    ll_var.append(l_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimadores - G Hedges y  ajustado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# lista con nombres de variables de salida\n",
    "var_out = [\"SEXO\", \"ETNIA\", \"DISCAPACIDAD\", \n",
    "            \"ESTRATO\",  \n",
    "           \"NATURALEZA\", \"ZONA\", \"DEPARTAMENTO\", \"MUNICIPIO\"] #\"EDAD\",#\"GRADO\",\n",
    "\n",
    "# bucle que recorre índice y dataframes\n",
    "for k_indx, k in enumerate(tab_out):\n",
    "    # Retrieve the DataFrame using eval() \n",
    "    df2 = eval(f\"{k}_1\")\n",
    "    current_vars = ll_var[k_indx]   \n",
    "    # lista con tantos nombres de variables de salida como categorias tenga la variable la tabla madre\n",
    "    var_df = [\n",
    "        # Repeat 'value' len(sublist) times for each element in sublist\n",
    "        [value] * len(sublist) for value, sublist in zip(var_out, ll_var)\n",
    "             ]\n",
    "    # indexar nombres de variable a su datafrane respectivo\n",
    "    names_current_vars = var_df[k_indx]  \n",
    "    # Se crean listas vacias l_dtab_out\n",
    "    exec(f\"l_d{k} = []\")\n",
    "    \n",
    "    # recorre dos listas (categorias var) y (nombres var)\n",
    "    for i, m in zip(current_vars, names_current_vars):\n",
    "        # indices para dataframes tab_out_1\n",
    "        colnv = (0, i)  \n",
    "        colvic = (1, i)\n",
    "        # crea formula\n",
    "        numerador = df2.loc[colnv, \"MEDIA\"] - df2.loc[colvic, \"MEDIA\"]\n",
    "        denominador = np.sqrt(\n",
    "                    (\n",
    "                        (\n",
    "                            (df2.loc[colnv, \"UNIVERSO\"] - 1)* df2.loc[colnv, \"VARIANZA\"]\n",
    "                        )\n",
    "                        + (\n",
    "                            (df2.loc[colvic, \"UNIVERSO\"] - 1) * df2.loc[colvic, \"VARIANZA\"]\n",
    "                        )\n",
    "                    ) \n",
    "                    / (\n",
    "                        df2.loc[colnv, \"UNIVERSO\"] +\n",
    "                       df2.loc[colvic, \"UNIVERSO\"] \n",
    "                       - 2\n",
    "                    )\n",
    "                        )\n",
    "        # crea dataframe con variable asociada a cada dataframes de tab_out_1\n",
    "        ds = pd.DataFrame({\n",
    "            f\"{m}\": [i],\n",
    "            \"NUMERADOR\": [numerador],\n",
    "            \"DENOMINADOR\": [denominador]\n",
    "        })\n",
    "        # Append dfs to the list\n",
    "        eval(f\"l_d{k}\").append(ds)\n",
    "    # se crean dfs tab_out_2: \n",
    "    exec(f'''{k}_2 = pd.concat(eval(\"l_d{k}\"), axis=0, ignore_index=True)''')\n",
    "    # calcula G de Hedges\n",
    "    exec(f'''{k}_2[\"INDICADOR\"]  = {k}_2[\"NUMERADOR\"] / {k}_2[\"DENOMINADOR\"]''')\n",
    "    # listas vacias l_ind_adjtab_out para indicador ajustado\n",
    "    exec(f\"l_ind_adj{k} = []\")\n",
    "    # recupera el valor del objeto string, en este caso un dataframe\n",
    "    df3 = eval(f\"{k}_2\")\n",
    "    for i, m in zip(current_vars, names_current_vars):\n",
    "        # indices para dfs tab_out_2\n",
    "        colnv = (0, i)  \n",
    "        colvic = (1, i)\n",
    "        # calcula indicador ajustado\n",
    "        ind_ajustado = df3.set_index(m).loc[i, \"INDICADOR\"] * ( 1 - \n",
    "                                        (3 / (\n",
    "                                                (\n",
    "                                                4 * (df2.loc[colnv, \"UNIVERSO\"] + \n",
    "                                                     df2.loc[colvic, \"UNIVERSO\"])\n",
    "                                                ) - 1\n",
    "                                            )\n",
    "                                        )\n",
    "                                     )\n",
    "        # crea df con variable y categoria asociadas a dfs de tab_out_1 y tab_out_2\n",
    "        ds2 = pd.DataFrame({\n",
    "            f\"{m}\": [i],\n",
    "            \"INDICADOR_AJUS\": [ind_ajustado]\n",
    "        })\n",
    "        # crea lista con dfs l_ind_adjtab_out\n",
    "        eval(f\"l_ind_adj{k}\").append(ds2)\n",
    "    # se crean dfs tab_out_2b: \n",
    "    exec(f'''{k}_2b = pd.concat(eval(\"l_ind_adj{k}\"), axis=0, ignore_index=True)''')\n",
    "    # se crean dfs tab_out_3, concatenando tab_out_2 y tab_out_2b. Se elimina índice\n",
    "    exec(f'''{k}_3 = pd.concat([eval(f\"{k}_2\"), eval(f\"{k}_2b\")], axis=1).reset_index(drop=True)''')\n",
    "    # se crean otros dfs para evitar interrupciones cuando se corra el código en bloque más de una vez\n",
    "    exec(f'''{k}_4 = eval(f\"{k}_3\").loc[:, ~eval(f\"{k}_3\").columns.duplicated()]''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etiquetar variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sexo\n",
    "sex_4.loc[:,\"SEXO\"] = sex_4[\"SEXO\"].replace([\"F\", \"M\"], \n",
    "                    [\"Mujer\", \"Hombre\"])\n",
    "#etnia\n",
    "etni_4.loc[:,\"ETNIA\"] = etni_4[\"ETNIA\"].replace([0,1,2,3,4,5,6,7], \n",
    "                                    [\"No aplica\", \"Indígenas\", \n",
    "                                    \"Negritudes\", \"Rrom\", \n",
    "                                     \"Otras Étnias\", \n",
    "                                     \"Raizales\", \"Afrodescendientes\",\n",
    "                                     \"Palenqueros\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agregar codigo divipola"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "## dejar solo la tabla de valor únicos de ifces por municipio\n",
    "reduc_icfes = icfes_f[[\"COLE_COD_DEPTO_UBICACION\",\"COLE_DEPTO_UBICACION\",\n",
    "                      \"COLE_COD_MCPIO_UBICACION\", \"COLE_MCPIO_UBICA2\"]]\n",
    "# mun\n",
    "dane_mun_icf = reduc_icfes.drop_duplicates(subset=['COLE_MCPIO_UBICA2'])\n",
    "# dpto\n",
    "dane_dpto_icf = reduc_icfes.drop_duplicates(subset=['COLE_COD_DEPTO_UBICACION'])\n",
    "# merge mun\n",
    "mun_4 = mun_4.merge(dane_mun_icf[[\"COLE_COD_MCPIO_UBICACION\", \"COLE_MCPIO_UBICA2\"]],\n",
    "            how= \"left\", left_on= \"MUNICIPIO\", right_on = \"COLE_MCPIO_UBICA2\",\n",
    "            validate= \"1:m\")\n",
    "# drop column\n",
    "mun_4.drop(columns=\"COLE_MCPIO_UBICA2\", inplace=True)\n",
    "# add zero to left\n",
    "mun_4[\"COLE_COD_MCPIO_UBICACION\"] = pd.to_numeric(mun_4[\"COLE_COD_MCPIO_UBICACION\"], downcast=\"integer\").astype(str).str.zfill(5)\n",
    "# reorder\n",
    "mun_4 = mun_4[['COLE_COD_MCPIO_UBICACION','MUNICIPIO', 'NUMERADOR', \n",
    "    'DENOMINADOR', 'INDICADOR', 'INDICADOR_AJUS']]\n",
    "# merge dpto\n",
    "dpto_4 = dpto_4.merge(dane_dpto_icf[[\"COLE_COD_DEPTO_UBICACION\",\"COLE_DEPTO_UBICACION\"]],\n",
    "            how= \"left\", left_on= \"DEPARTAMENTO\", right_on = \"COLE_DEPTO_UBICACION\",\n",
    "            validate= \"1:m\")\n",
    "# drop column \n",
    "dpto_4.drop(columns=\"COLE_DEPTO_UBICACION\", inplace=True)\n",
    "\n",
    "# eliminate last zero to rigth and add zero to left\n",
    "def remove_last_zero(s):\n",
    "    s = str(s)  # Ensure the value is a string\n",
    "    if s.endswith('0'):\n",
    "        return s[:-1]  # Remove the last character\n",
    "    return s\n",
    "\n",
    "dpto_4['COLE_COD_DEPTO_UBICACION'] = dpto_4['COLE_COD_DEPTO_UBICACION'].apply(remove_last_zero).astype(str).str.zfill(2)\n",
    "# reorder\n",
    "dpto_4 = dpto_4[['COLE_COD_DEPTO_UBICACION', 'DEPARTAMENTO', 'NUMERADOR',\n",
    "             'DENOMINADOR', 'INDICADOR','INDICADOR_AJUS']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ruta de salida\n",
    "p2 = \"C:/Users/ivan.corredor/2024/IGED_desempeño/salidas\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "salida = p2 + \"/res_desempeño_2024.xlsx\"\n",
    "writer = pd.ExcelWriter(salida)\n",
    "\n",
    "# Generar las tablas y nombres de pestañas de acuerdo con el número de enfoques.\n",
    "# iniciando por la tabla general\n",
    "tablas = [grl_2]\n",
    "pestañas = [\"General\"]\n",
    "\n",
    "for k in tab_out:\n",
    "    # nombre de tablas y pestañas\n",
    "   #The extend() method allows you to append elements from an iterable (like a list)\n",
    "   #to the end of another list.\n",
    "    tablas.extend([eval(f\"{k}_1\"), eval(f\"{k}_4\")])\n",
    "    pestañas.extend([f\"{k}_1\", f\"{k}_4\"])\n",
    "\n",
    "#exportar cada tabla como una pestaña del archivo excel\n",
    "for i,j in zip(tablas, pestañas):\n",
    "    i.to_excel(writer, sheet_name = j, header = True, index= True)\n",
    "\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
